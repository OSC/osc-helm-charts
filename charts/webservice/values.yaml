global:
  imagePullSecret:
    name: osc-registry
    registry: docker-registry.osc.edu
    username: robot$webservices-read
    password:
  nodeSelectorRole: webservices
  storageClass: webservices-nfs-client
appType: rails
command: []
args: []
workingDir:
env: []
defaultCommand:
  rails: ['bundle', 'exec', 'passenger', 'start']
  rshiny: ['/bin/passenger', 'start']
  none: []
defaultArgs:
  rails:
    # Set by PASSENGER_PORT env var
    # - "--port={{ .Values.service.port }}"
    - "--min-instances=1"
    - "--sticky-sessions"
    - "--start-timeout=180"
    - "--environment=production"
    - "--disable-security-update-check"
    - "--disable-anonymous-telemetry"
    - "--log-file=/dev/stdout"
    - "--pid-file=/tmp/passenger-{{ .name }}.pid"
  rshiny:
    # Set by PASSENGER_PORT env var
    # - "--port={{ .Values.service.port }}"
    - "--min-instances=1"
    - "--sticky-sessions"
    - "--start-timeout=180"
    - "--environment=production"
    - "--disable-security-update-check"
    - "--disable-anonymous-telemetry"
    - "--log-file=/dev/stdout"
    - "--pid-file=/tmp/passenger-{{ .name }}.pid"
    - "--app-start-command"
    - '{{ .startCommand | default "R --no-save --slave -f /app/entrypoint.R --args $$PORT" }}'
  none: []
containers:
  - name: '{{ include "webservice.name" . }}'
    port: ~
    portName: http
    startCommand: ~
    probePath: ~
    probeType: ~
    ingressPath: /
    auth: ~

image:
  repository:
  tag:
  pullPolicy: IfNotPresent

mounts:
  home: ''
  roDir: {}
  socket: {}

nodeSelector: {}

podSecurityContext:
  runAsNonRoot: true

podResources:
  limits:
    cpu: 4
    memory: 4Gi
  requests:
    cpu: 1
    memory: 256Mi

# Also pulled from global.env.$environment.replicas
# replicas: 1

podDistributionBudget:
  minAvailable: 1

secrets: {}
envSecrets: {}

debugGroups: []

alert:
  # Also pulled from global.env.$environment.alert.receiver
  receiver:

service:
  port: 3000
  annotations: {}
  typeAnnotations:
    rshiny:
      prometheus.io/probe_module: http
      prometheus.io/probe_scheme: http

probes:
  type: ~
  path: /
  typeDefaults:
    rshiny: tcpSocket
startupProbe:
  httpGet:
    path: '{{ .probePath | default .Values.probes.path }}'
    port: '{{ .portName | default .name }}'
  tcpSocket:
    port: '{{ .portName | default .name }}'
  failureThreshold: 12
  periodSeconds: 10
  timeoutSeconds: 5
livenessProbe:
  httpGet:
    path: '{{ .probePath | default .Values.probes.path }}'
    port: '{{ .portName | default .name }}'
  tcpSocket:
    port: '{{ .portName | default .name }}'
  failureThreshold: 6
  periodSeconds: 10
  timeoutSeconds: 5
readinessProbe:
  httpGet:
    path: '{{ .probePath | default .Values.probes.path }}'
    port: '{{ .portName | default .name }}'
  tcpSocket:
    port: '{{ .portName | default .name }}'
  failureThreshold: 6
  periodSeconds: 10
  timeoutSeconds: 5

initContainers: {}
init:
  podResources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 256Mi

ingress:
  # Also pulled from global.env.$environment.ingress.host
  host: ""
  # Also pulled from global.env.$environment.ingress.hostAlias
  hostAlias: ""
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/proxy-buffer-size: "8k"
  rShinyAnnotations:
    nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    nginx.ingress.kubernetes.io/server-snippets: |
     location / {
       proxy_http_version 1.1;
       proxy_set_header Upgrade $http_upgrade;
       proxy_set_header Connection $connection_upgrade;
       proxy_buffering off;
      }

auth:
  enable: true
  clientID: kubernetes-{{ include "webservice.name" . }}
  clientSecret:
  cookieSecret:
  cookieName: _{{ include "osc.common.serviceAccountValue" . }}{{ include "osc.common.environment" . }}
  # Also pulled from global.env.$environment.auth.idpHost
  idpHost:
  oidcIssuerURL: https://$(IDP_HOST)/realms/osc
  # Also pulled from global.env.$environment.auth.accessGroup
  allowGroups:
  skipAuthRoute:
  image:
    repository: quay.io/oauth2-proxy/oauth2-proxy
    tag: v7.1.3
    pullPolicy: IfNotPresent
  service:
    port: 4180
    annotations:
      prometheus.io/probe_module: http-healthz
      prometheus.io/probe_path: /ping
  metricsService:
    type: ClusterIP
    port: 8080
    annotations:
      prometheus.io/scrape: 'true'
      prometheus.io/path: /metrics
  podResources:
    limits:
      cpu: 200m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 64Mi
  ingress:
    className: ~
    annotations:
      prometheus.io/probe_path: /ping
  # Also pulled from global.env.$environment.auth.replicas
  # replicas: 1
  podDistributionBudget:
    minAvailable: 1

data:
  enable: false
  storageClass: '{{ .Values.global.storageClass }}'
  storageSize: 10Gi
  path: /data

database:
  enable: false
  imagePullSecret:
    enable: false
  host: '{{ include "webservice.name" . }}-mariadb'
  user: '{{ .Values.database.mariadb.auth.username }}'
  password: '{{ .Values.database.mariadb.auth.password }}'
  name: '{{ .Values.database.mariadb.auth.database }}'
  url: mysql2://{{ tpl .Values.database.user . }}:$(DATABASE_PASSWORD)@{{ tpl .Values.database.host . }}:3306/{{ tpl .Values.database.name . }}
  mariadb:
    enable: false
    networkPolicy:
      ingressRules:
        primaryAccessOnlyFrom:
          podSelector:
            app.kubernetes.io/name: '{{ include "webservice.name" . }}'
  postgresql:
    enable: false
    networkPolicy:
      ingressRules:
        primaryAccessOnlyFrom:
          podSelector:
            app.kubernetes.io/name: '{{ include "webservice.name" . }}'

hook:
  image:
    repository: docker-registry.osc.edu/kubernetes/bitnami/kubectl
    tag: '1.27.14'
# Used for network policies
ingressName: ingress-nginx
prometheusName: prometheus
